features_list = ['poi','salary','bonus','long_term_incentive','exercised_stock_options','ratio_messages'] # You will need to use more features
Accuracy: 0.80050	Precision: 0.64985	Recall: 0.43800	F1: 0.52330	F2: 0.46855
	Total predictions: 4000	True positives:  438	False positives:  236	False negatives:  562	True negatives: 2764
-----------------------	
features_list = ['poi','salary','bonus','long_term_incentive','exercised_stock_options','from_poi_to_this_person'] 
	GaussianNB()
	Accuracy: 0.81075	Precision: 0.69134	Recall: 0.43900	F1: 0.53700	F2: 0.47357
	Total predictions: 4000	True positives:  439	False positives:  196	False negatives:  561	True negatives: 2804	
--------------------
features_list = ['poi','salary','bonus','long_term_incentive','exercised_stock_options','ratio_to_from_messages'] 	
	GaussianNB()
	Accuracy: 0.78050	Precision: 0.58069	Recall: 0.43900	F1: 0.50000	F2: 0.46152
	Total predictions: 4000	True positives:  439	False positives:  317	False negatives:  561	True negatives: 2683
----------------	
features_list = ['poi','salary','long_term_incentive','exercised_stock_options','ratio_to_from_messages']
	GaussianNB()
	Accuracy: 0.78075	Precision: 0.58554	Recall: 0.42100	F1: 0.48982	F2: 0.44607
	Total predictions: 4000	True positives:  421	False positives:  298	False negatives:  579	True negatives: 2702
------------------
features_list = ['poi','salary','long_term_incentive','total_stock_value','ratio_to_from_messages']	
GaussianNB()
	Accuracy: 0.80660	Precision: 0.52973	Recall: 0.29400	F1: 0.37814	F2: 0.32272
	Total predictions: 5000	True positives:  294	False positives:  261	False negatives:  706	True negatives: 3739
----------------------
features_list = ['poi','bonus','long_term_incentive','exercised_stock_options','from_poi_to_this_person']	
GaussianNB()
	Accuracy: 0.83025	Precision: 0.77816	Recall: 0.44900	F1: 0.56944	F2: 0.49050
	Total predictions: 4000	True positives:  449	False positives:  128	False negatives:  551	True negatives: 2872
------------------------Decision Tree-------------------
features_list = ['poi','salary','bonus','long_term_incentive','exercised_stock_options','ratio_messages'] # You will need to use more features	
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            random_state=None, splitter='best')
	Accuracy: 0.66950	Precision: 0.33868	Recall: 0.33800	F1: 0.33834	F2: 0.33814
	Total predictions: 4000	True positives:  338	False positives:  660	False negatives:  662	True negatives: 2340
--------------------	

features_list = ['poi','salary','bonus','long_term_incentive','exercised_stock_options','from_poi_to_this_person'] 
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            random_state=None, splitter='best')
	Accuracy: 0.72950	Precision: 0.46139	Recall: 0.49000	F1: 0.47527	F2: 0.48400
	Total predictions: 4000	True positives:  490	False positives:  572	False negatives:  510	True negatives: 2428

--------------------
features_list = ['poi','salary','long_term_incentive','exercised_stock_options','ratio_to_from_messages'] 	
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            random_state=None, splitter='best')
	Accuracy: 0.73075	Precision: 0.45528	Recall: 0.39200	F1: 0.42128	F2: 0.40321
	Total predictions: 4000	True positives:  392	False positives:  469	False negatives:  608	True negatives: 2531
	
-------
features_list = ['poi','salary','long_term_incentive','exercised_stock_options','ratio_to_from_messages'] 
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            random_state=None, splitter='best')
	Accuracy: 0.72950	Precision: 0.45244	Recall: 0.39000	F1: 0.41890	F2: 0.40107
	Total predictions: 4000	True positives:  390	False positives:  472	False negatives:  610	True negatives: 2528	
-----
features_list = ['poi','salary','long_term_incentive','total_stock_value','ratio_to_from_messages']aaa
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            random_state=None, splitter='best')
	Accuracy: 0.65800	Precision: 0.22901	Recall: 0.30000	F1: 0.25974	F2: 0.28249
	Total predictions: 5000	True positives:  300	False positives: 1010	False negatives:  700	True negatives: 2990	
	
	
	
	-------PCA----
	features_list = ['poi','salary','bonus','long_term_incentive','exercised_stock_options','ratio_to_from_messages']
pca = RandomizedPCA(n_components=2,whiten=True).fit(features_train)
pca=pca.fit(features_train)

Accuracy: 0.78050	Precision: 0.58069	Recall: 0.43900	F1: 0.50000	F2: 0.46152
	Total predictions: 4000	True positives:  439	False positives:  317	False negatives:  561	True negatives: 2683
	
	----------------
	features_list = ['poi','salary','bonus','long_term_incentive','exercised_stock_options','from_poi_to_this_person']	
	from sklearn import grid_search, datasets
parameters = {'criterion':('gini', 'entropy'),'splitter':('best','random'), 'min_samples_split':[2,3,4,5,6,7,8,9,10]}
dtr = DecisionTreeClassifier()
clf = grid_search.GridSearchCV(dtr, parameters)
	Accuracy: 0.74650	Precision: 0.49067	Recall: 0.36800	F1: 0.42057	F2: 0.38737
	Total predictions: 4000	True positives:  368	False positives:  382	False negatives:  632	True negatives: 2618
	
	
	---------------------SVM---------------